<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>19.  Transformers - Machine Learning for Everyone!</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="chapter_1.html"><strong aria-hidden="true">1.</strong> Quick Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="sup.html"><strong aria-hidden="true">1.1.</strong> Supervised Learning</a></li><li class="chapter-item expanded "><a href="unsup.html"><strong aria-hidden="true">1.2.</strong> Unsupervised Learning</a></li></ol></li><li class="chapter-item expanded "><a href="chapter_2.html"><strong aria-hidden="true">2.</strong> Basic Linear Algebra needed</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="eigen.html"><strong aria-hidden="true">2.1.</strong> Eigenvectors </a></li><li class="chapter-item expanded "><a href="chapter_2-ref.html"><strong aria-hidden="true">2.2.</strong> References</a></li></ol></li><li class="chapter-item expanded "><a href="ml_models.html"><strong aria-hidden="true">3.</strong> ML Models</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="word2vec.html"><strong aria-hidden="true">3.1.</strong> Word2Vec</a></li><li class="chapter-item expanded "><a href="glove.html"><strong aria-hidden="true">3.2.</strong> GloVe</a></li></ol></li><li class="chapter-item expanded "><a href="dl.html"><strong aria-hidden="true">4.</strong> Deep Learning</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="nn.html"><strong aria-hidden="true">4.1.</strong> Neural Network</a></li><li class="chapter-item expanded "><a href="grad_descent.html"><strong aria-hidden="true">4.2.</strong> Gradient descent</a></li><li class="chapter-item expanded "><a href="back_propagation.html"><strong aria-hidden="true">4.3.</strong> Back Propagation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="bp_calc.html"><strong aria-hidden="true">4.3.1.</strong> Calculus</a></li></ol></li><li class="chapter-item expanded "><a href="act_func.html"><strong aria-hidden="true">4.4.</strong> Activation Function</a></li><li class="chapter-item expanded "><a href="cnn.html"><strong aria-hidden="true">4.5.</strong> Convolutional Neural Networks</a></li><li class="chapter-item expanded "><a href="rnn.html"><strong aria-hidden="true">4.6.</strong> Recurrent Neural Networks</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="mnist.html"><strong aria-hidden="true">4.6.1.</strong> MNIST</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="tf.html"><strong aria-hidden="true">5.</strong> Tensorflow</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tfjs.html"><strong aria-hidden="true">5.1.</strong> TensorFlow.js</a></li></ol></li><li class="chapter-item expanded "><a href="torch.html"><strong aria-hidden="true">6.</strong> PyTorch</a></li><li class="chapter-item expanded "><a href="chapter_7.html"><strong aria-hidden="true">7.</strong> Transformers</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="bert.html"><strong aria-hidden="true">7.1.</strong> BERT</a></li><li class="chapter-item expanded "><a href="GPT.html"><strong aria-hidden="true">7.2.</strong> GPT</a></li><li class="chapter-item expanded "><a href="T5.html"><strong aria-hidden="true">7.3.</strong> T5</a></li><li class="chapter-item expanded "><a href="copilot.html"><strong aria-hidden="true">7.4.</strong> GitHub Copilot</a></li><li class="chapter-item expanded "><a href="chapter_7_ref.html"><strong aria-hidden="true">7.5.</strong> References</a></li></ol></li><li class="chapter-item expanded "><a href="sf_e.html"><strong aria-hidden="true">8.</strong> Salesforce Einstein</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="sf_ml.html"><strong aria-hidden="true">8.1.</strong> Machine Learning</a></li><li class="chapter-item expanded "><a href="sf_nlp.html"><strong aria-hidden="true">8.2.</strong> Natural Language Processing</a></li><li class="chapter-item expanded "><a href="sf_cv.html"><strong aria-hidden="true">8.3.</strong> Computer Vision</a></li></ol></li><li class="chapter-item expanded "><a href="gcp.html"><strong aria-hidden="true">9.</strong> Google Cloud Platform</a></li><li class="chapter-item expanded "><a href="pu.html"><strong aria-hidden="true">10.</strong> Processing Units</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="cpu.html"><strong aria-hidden="true">10.1.</strong> CPU</a></li><li class="chapter-item expanded "><a href="gpu.html"><strong aria-hidden="true">10.2.</strong> GPU</a></li><li class="chapter-item expanded "><a href="tpu.html"><strong aria-hidden="true">10.3.</strong> TPU</a></li></ol></li><li class="chapter-item expanded "><a href="ml_pl.html"><strong aria-hidden="true">11.</strong> ML Pipelines</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ml-ops.html"><strong aria-hidden="true">11.1.</strong> ML ops</a></li><li class="chapter-item expanded "><a href="tfs.html"><strong aria-hidden="true">11.2.</strong> TensorFlow Serving</a></li><li class="chapter-item expanded "><a href="tfx.html"><strong aria-hidden="true">11.3.</strong> TensorFlow Extended</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="apache_airflow.html"><strong aria-hidden="true">11.3.1.</strong> Apache Airflow</a></li><li class="chapter-item expanded "><a href="apache_beam.html"><strong aria-hidden="true">11.3.2.</strong> Apache Beam</a></li><li class="chapter-item expanded "><a href="kubeflow.html"><strong aria-hidden="true">11.3.3.</strong> Kubeflow</a></li></ol></li><li class="chapter-item expanded "><a href="automl.html"><strong aria-hidden="true">11.4.</strong> AutoML</a></li><li class="chapter-item expanded "><a href="kubernetes.html"><strong aria-hidden="true">11.5.</strong> Kubernetes</a></li></ol></li><li class="chapter-item expanded "><a href="speedup.html"><strong aria-hidden="true">12.</strong> Speedup</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="jax.html"><strong aria-hidden="true">12.1.</strong> JAX</a></li><li class="chapter-item expanded "><a href="closure.html"><strong aria-hidden="true">12.2.</strong> Closures and Decorators</a></li><li class="chapter-item expanded "><a href="jax_ref.html"><strong aria-hidden="true">12.3.</strong> References</a></li></ol></li><li class="chapter-item expanded "><a href="openai.html"><strong aria-hidden="true">13.</strong> OpenAI</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="openai-api.html"><strong aria-hidden="true">13.1.</strong> API</a></li><li class="chapter-item expanded "><a href="openai-chat.html"><strong aria-hidden="true">13.2.</strong> Chat</a></li><li class="chapter-item expanded "><a href="openai-summarize.html"><strong aria-hidden="true">13.3.</strong> Summarize</a></li><li class="chapter-item expanded "><a href="openai-tldr.html"><strong aria-hidden="true">13.4.</strong> TLDR</a></li><li class="chapter-item expanded "><a href="open-translate.html"><strong aria-hidden="true">13.5.</strong> Translate</a></li><li class="chapter-item expanded "><a href="openai-codex.html"><strong aria-hidden="true">13.6.</strong> Codex</a></li></ol></li><li class="chapter-item expanded "><a href="inspire.html"><strong aria-hidden="true">14.</strong> Inspirations</a></li><li class="chapter-item expanded "><a href="datasets.html"><strong aria-hidden="true">15.</strong> Datasets</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="datasets/boston.html"><strong aria-hidden="true">15.1.</strong> Boston Housing</a></li></ol></li><li class="chapter-item expanded "><a href="industry/ml-industry.html"><strong aria-hidden="true">16.</strong> Building ML for Industries</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="industry/lfitem-magmt.html"><strong aria-hidden="true">16.1.</strong> Lost-Found Item Management</a></li></ol></li><li class="chapter-item expanded "><a href="hardware/hardware.html"><strong aria-hidden="true">17.</strong> Hardware</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="hardware/raspi.html"><strong aria-hidden="true">17.1.</strong> Raspberry Pi</a></li></ol></li><li class="chapter-item expanded "><a href="conversational-ai.html"><strong aria-hidden="true">18.</strong> Conversational-AI</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="chatbots.html"><strong aria-hidden="true">18.1.</strong> Chatbots</a></li><li class="chapter-item expanded "><a href="ebot.html"><strong aria-hidden="true">18.2.</strong> Einstein Bots</a></li><li class="chapter-item expanded "><a href="DeepPavlov.html"><strong aria-hidden="true">18.3.</strong> DeepPavlov</a></li><li class="chapter-item expanded "><a href="dialogflow.html"><strong aria-hidden="true">18.4.</strong> Dialogflow</a></li><li class="chapter-item expanded "><a href="rasa.html"><strong aria-hidden="true">18.5.</strong> Rasa</a></li></ol></li><li class="chapter-item expanded "><a href="transformers.html" class="active"><strong aria-hidden="true">19.</strong> Transformers</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="transformers/gpt.html"><strong aria-hidden="true">19.1.</strong> GPT</a></li><li class="chapter-item expanded "><a href="transformers/build-gpt.html"><strong aria-hidden="true">19.2.</strong> Building GPT</a></li></ol></li><li class="chapter-item expanded "><a href="tools.html"><strong aria-hidden="true">20.</strong> Tools</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="iac.html"><strong aria-hidden="true">20.1.</strong> Infrastructure as code</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Machine Learning for Everyone!</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="19--transformers"><a class="header" href="#19--transformers">19.  Transformers</a></h1>
<h2 id="papers"><a class="header" href="#papers">Papers</a></h2>
<ul>
<li>
<p><a href="https://arxiv.org/pdf/1706.03762.pdf">Attention is All You Need</a></p>
<ul>
<li>
<p>A new simple network architecture, the <strong>Transformer</strong>, based solely on <strong>attention mechanisms</strong>, </p>
<ul>
<li>dispensing with recurrence and convolutions entirely</li>
</ul>
</li>
<li>
<p>Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.</p>
</li>
<li>
<p>sequence modeling tasks are based on</p>
<ul>
<li>LSTM  (long short-term memory)</li>
<li>language modeling and machine translation</li>
<li>generate a sequence of hidden states ht as a function of the previous hidden state ht−1 1 and the input for position t. This inherently sequential nature precludes <strong>parallelization</strong> within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples.</li>
</ul>
</li>
<li>
<p><strong>Attention mechanisms</strong> have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences</p>
</li>
<li>
<p>Transformer</p>
<ul>
<li>a model architecture eschewing recurrence and instead relying entirely on <strong>an attention mechanism</strong> to draw <strong>global dependencies</strong> between input and output.</li>
<li>allows for significantly more <strong>parallelization</strong> and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.</li>
</ul>
</li>
<li>
<p>Usually we compute the hidden representations in parallel for all input and output positions. </p>
</li>
<li>
<p>In these models,the <strong>number of operations</strong> required to relate signals from two arbitrary input or output positions grows in the <strong>distance between positions</strong></p>
</li>
<li>
<p>This makes it more difficult to learn dependencies between distant positions </p>
</li>
<li>
<p>In Transformer this is reduced to a <strong>constant number of operations</strong></p>
</li>
<li>
<p><strong>Self-attention</strong>, sometimes called intra-attention</p>
<ul>
<li>attention mechanism <strong>relating different positions</strong> of a single sequence in order to compute a representation of the sequence.</li>
<li>relying entirely on self-attention to compute representations of its input and output without using sequence aligned RNNs or convolution. </li>
</ul>
</li>
</ul>
<p><img src="img/transform-1.png" alt="transformer" /></p>
<h3 id="encoder"><a class="header" href="#encoder">Encoder</a></h3>
<p><a href="http://localhost:7010/github-mirror/mohan-chinnappan-n5.github.io/wc/wc.html?c=1">wc</a></p>
<ul>
<li>
<p>The encoder is composed of a stack of <code>N = 6</code> identical layers</p>
</li>
<li>
<p>Each Layer has  2 Sub Layers, each Sub Layer has:</p>
<ul>
<li>multi-head <strong>self-attention</strong></li>
<li>position-wise fully connected feed-forward network</li>
</ul>
</li>
<li>
<p><code>Sublayer(x)</code> is the function implemented by the sub-layer itself.</p>
</li>
<li>
<p>Output of each sub-layer is <code>LayerNorm(x + Sublayer(x))</code></p>
</li>
<li>
<p>To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension <code>dmodel = 512</code></p>
</li>
</ul>
<h3 id="decoder"><a class="header" href="#decoder">Decoder</a></h3>
<ul>
<li>also composed of a stack of <code>N = 6</code> identical layers</li>
<li>In addition to the two sub-layers in each encoder layer, the decoder <strong>inserts a third sub-layer</strong>
<ul>
<li>which performs multi-head <strong>attention over the output</strong> of the encoder stack</li>
<li>Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization</li>
</ul>
</li>
<li>We also modify the self-attention sub-layer in the decoder stack to <strong>prevent positions from attending to subsequent positions</strong>. 
<ul>
<li>This masking, combined with fact that the output embeddings are offset by one position
<ul>
<li>ensures that the predictions for position <code>i</code> can depend only on the known outputs at positions   <code>&lt; i</code>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="attention"><a class="header" href="#attention">Attention</a></h3>
<ul>
<li>Can be described as mapping a <strong>query</strong> and a <strong>set of key-value pairs</strong> to an <strong>output</strong>,</li>
<li>where the query, keys, values, and output are all <strong>vectors</strong>.</li>
<li>The output is computed as a <strong>weighted sum of the values</strong>
<ul>
<li>where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="https://arxiv.org/pdf/2005.14165.pdf">Language Models are Few-Shot Learners</a></p>
</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="rasa.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="transformers/gpt.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="rasa.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="transformers/gpt.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script type="text/javascript">
            var socket = new WebSocket("ws://localhost:5000/__livereload");
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>
