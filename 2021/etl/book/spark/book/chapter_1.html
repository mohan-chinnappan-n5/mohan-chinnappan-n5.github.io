<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Introduction - ETL with Spark</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="chapter_1.html" class="active"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="scala.html"><strong aria-hidden="true">2.</strong> Scala</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">ETL with Spark</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="chapter-1---introduction-to-spark"><a class="header" href="#chapter-1---introduction-to-spark">Chapter 1 - Introduction to Spark</a></h1>
<h2 id="data-sources-connectivity"><a class="header" href="#data-sources-connectivity">Data Sources Connectivity</a></h2>
<p><img src="img/sparkml-1.png" alt="spark -1" /></p>
<h2 id="databricks-notebook"><a class="header" href="#databricks-notebook">Databricks notebook</a></h2>
<pre><code>%run ./Mount-Datasets


</code></pre>
<h2 id="parquet"><a class="header" href="#parquet">Parquet</a></h2>
<p>Parquet is an open source file format built to handle <strong>flat columnar storage data formats</strong>.</p>
<ul>
<li>
<p>Operates well with complex data in large volumes.</p>
</li>
<li>
<p>It is known for its both <em>performant data compression</em> and its ability to handle a wide variety of <em>encoding</em> types. </p>
</li>
<li>
<p>Deploys Google's <em>record-shredding and assembly algorithm</em> that can address complex data structures within data storage. </p>
</li>
<li>
<p>Some Parquet benefits include:</p>
<ul>
<li>
<p>Fast queries that can <em>fetch specific column values</em> without reading full row data</p>
</li>
<li>
<p>Highly efficient column-wise compression</p>
</li>
<li>
<p>High compatibility with with <strong>OLAP</strong></p>
</li>
</ul>
</li>
</ul>
<h3 id="parquet-vs-csv"><a class="header" href="#parquet-vs-csv">Parquet vs CSV</a></h3>
<ul>
<li>
<p>CSV is simple and the most widely used data format. Row oriented format</p>
</li>
<li>
<p>Parquet is column oriented</p>
</li>
<li>
<p>Row-oriented formats are optimized for <strong>OLTP</strong> workloads</p>
</li>
<li>
<p>Column-oriented formats are better suited for <strong>analytical</strong> workloads.</p>
</li>
<li>
<p>Column-oriented databases such as AWS Redshift Spectrum bill by the <strong>amount data scanned per query</strong></p>
<ul>
<li>Therefore, converting CSV to Parquet with partitioning and compression <strong>lowers overall costs</strong> and improves performance</li>
</ul>
</li>
<li>
<p>Parquet has helped its users reduce storage requirements by at least <strong>one-third on large datasets</strong>, in addition, it greatly improves <strong>scan and de-serialization time</strong>, hence the overall costs.</p>
</li>
</ul>
<h3 id="data"><a class="header" href="#data">Data</a></h3>
<table><thead><tr><th>Name</th><th>Qty</th><th>State</th></tr></thead><tbody>
<tr><td>Apple</td><td>100</td><td>NH</td></tr>
<tr><td>Pear</td><td>200</td><td>MA</td></tr>
<tr><td>Peach</td><td>400</td><td>CA</td></tr>
</tbody></table>
<ul>
<li>Row-Oriented Store</li>
</ul>
<table><thead><tr><th>RowID</th><th>Value</th></tr></thead><tbody>
<tr><td>Row#1</td><td>Apple</td></tr>
<tr><td>Row#1</td><td>100</td></tr>
<tr><td>Row#1</td><td>NH</td></tr>
<tr><td>---</td><td>---</td></tr>
<tr><td>Row#2</td><td>Pear</td></tr>
<tr><td>Row#2</td><td>100</td></tr>
<tr><td>Row#2</td><td>MA</td></tr>
<tr><td>---</td><td>---</td></tr>
<tr><td>Row#3</td><td>Peach</td></tr>
<tr><td>Row#3</td><td>400</td></tr>
<tr><td>Row#3</td><td>CA</td></tr>
</tbody></table>
<ul>
<li>Col-Oriented Store</li>
</ul>
<table><thead><tr><th>Col</th><th>Value</th></tr></thead><tbody>
<tr><td>Name</td><td>Apple</td></tr>
<tr><td>Name</td><td>Pear</td></tr>
<tr><td>Name</td><td>Peach</td></tr>
<tr><td>---</td><td>---</td></tr>
<tr><td>Qty</td><td>100</td></tr>
<tr><td>Qty</td><td>200</td></tr>
<tr><td>Qty</td><td>400</td></tr>
<tr><td>---</td><td>---</td></tr>
<tr><td>State</td><td>NH</td></tr>
<tr><td>State</td><td>MA</td></tr>
<tr><td>State</td><td>CA</td></tr>
</tbody></table>
<h2 id="working-with-parquet-file-example"><a class="header" href="#working-with-parquet-file-example">Working with Parquet file example</a></h2>
<pre><code class="language-scala">

val data = Seq((&quot;Apple&quot;,100, &quot;NH&quot;),
              (&quot;Pear&quot;,200,   &quot;MA&quot;),
              (&quot;Peach&quot;,400,  &quot;CA&quot;)
)
              
val columns = Seq(&quot;name&quot;,&quot;qty&quot;,&quot;state&quot;)

import spark.sqlContext.implicits._
// data to dataFrame
val df = data.toDF(columns:_*)

// look at the df
df.show()
df.printSchema()


val fruitsFile = &quot;/tmp/fruits.parquet&quot;
// write this dataFrame to parquet file
df.write.parquet(fruitsFile)

// reading this parquet file into a dataFrame
val fruitsDF = df.read.parquet(fruitsFile)

 
// SQL queries on parquet file
fruitsDF.createOrReplaceTempView(&quot;FruitsParquetTable&quot;)
val parkSQL = spark.sql(&quot;SELECT * FROM FruitsParquetTable WHERE qty &gt;= 10 &quot;)





</code></pre>
<h2 id="spark-mllib"><a class="header" href="#spark-mllib">Spark MLlib</a></h2>
<ul>
<li>MLlib is Apache Spark's scalable machine learning library. </li>
</ul>
<iframe width="800" height="420" src="https://www.youtube.com/embed/DqihOzZl5jM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<h2 id="transformers-and-estimators"><a class="header" href="#transformers-and-estimators">Transformers and Estimators</a></h2>
<ul>
<li><a href="https://spark.apache.org/docs/latest/ml-guide.html">Spark ML Programming Guide</a></li>
</ul>
<h3 id="stringindexer"><a class="header" href="#stringindexer"><a href="https://spark.apache.org/docs/3.2.0/ml-features.html#stringindexer">StringIndexer</a></a></h3>
<table><thead><tr><th>id</th><th>category</th></tr></thead><tbody>
<tr><td>0</td><td>apple</td></tr>
<tr><td>1</td><td>mango</td></tr>
<tr><td>2</td><td>peach</td></tr>
<tr><td>3</td><td>apple</td></tr>
<tr><td>4</td><td>apple</td></tr>
<tr><td>5</td><td>peach</td></tr>
</tbody></table>
<p>category is a string column with three labels: “apple”, “mango”, and “peach”. 
Applying <strong>StringIndexer</strong> with category as the input column and categoryIndex as the output column, we should get the following:</p>
<table><thead><tr><th>id</th><th>category</th><th>categoryIndex</th></tr></thead><tbody>
<tr><td>0</td><td>apple</td><td>0.0</td></tr>
<tr><td>1</td><td>mango</td><td>2.0</td></tr>
<tr><td>2</td><td>peach</td><td>1.0</td></tr>
<tr><td>3</td><td>apple</td><td>0.0</td></tr>
<tr><td>4</td><td>apple</td><td>0.0</td></tr>
<tr><td>5</td><td>peach</td><td>1.0</td></tr>
</tbody></table>
<pre><code class="language-scala">
import org.apache.spark.ml.feature.StringIndexer

val df = spark.createDataFrame(
 Seq((0, &quot;apple&quot;), (1, &quot;mango&quot;), (2, &quot;peach&quot;), (3, &quot;apple&quot;), (4, &quot;apple&quot;), (5, &quot;peach&quot;))
).toDF(&quot;id&quot;, &quot;category&quot;)

val indexer = new StringIndexer()
 .setInputCol(&quot;category&quot;)
 .setOutputCol(&quot;categoryIndex&quot;)

val indexed = indexer.fit(df).transform(df)
indexed.show()

</code></pre>
<h3 id="onehotencoder"><a class="header" href="#onehotencoder">OneHotEncoder</a></h3>
<ul>
<li>maps a categorical feature, represented as a label index, to a binary vector with at most a single one-value indicating the <strong>presence of a specific feature value</strong> from among the set of all feature values.</li>
</ul>
<pre><code class="language-scala">
import org.apache.spark.ml.feature.OneHotEncoder

val df = spark.createDataFrame(Seq(
  (0.0, 1.0),
  (1.0, 0.0),
  (2.0, 1.0),
  (0.0, 2.0),
  (0.0, 1.0),
  (2.0, 0.0)
)).toDF(&quot;categoryIndex1&quot;, &quot;categoryIndex2&quot;)

// setup encoder - OneHotEncoder
val encoder = new OneHotEncoder()
  .setInputCols(Array(&quot;categoryIndex1&quot;, &quot;categoryIndex2&quot;))
  .setOutputCols(Array(&quot;categoryVec1&quot;, &quot;categoryVec2&quot;))

// fit it 
val model = encoder.fit(df)

// transform the df
val encoded = model.transform(df)

encoded.show()

</code></pre>
<h3 id="vectorassembler"><a class="header" href="#vectorassembler">VectorAssembler</a></h3>
<p>Spark ML  works on single column instead of array columns.</p>
<p>VectorAssembler is a transformer that combines a <strong>given list of columns</strong> into a <strong>single vector column</strong>. - It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees. </p>
<ul>
<li>VectorAssembler accepts the following input column types:
<ul>
<li>all numeric types, boolean type, and vector type. </li>
<li>In each row, the values of the input columns will be concatenated into a vector in the specified order.</li>
</ul>
</li>
</ul>
<table><thead><tr><th>id</th><th>hour</th><th>mobile</th><th>userFeatures</th><th>clicked</th></tr></thead><tbody>
<tr><td>0</td><td>18</td><td>1.0</td><td>[0.0, 10.0, 0.5]</td><td>1.0</td></tr>
</tbody></table>
<table><thead><tr><th>id</th><th>hour</th><th>mobile</th><th>userFeatures</th><th>clicked</th><th>features</th></tr></thead><tbody>
<tr><td>0</td><td>18</td><td>1.0</td><td>[0.0, 10.0, 0.5]</td><td>1.0</td><td>[18.0, 1.0, 0.0, 10.0, 0.5]</td></tr>
</tbody></table>
<pre><code class="language-scala">
import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.linalg.Vectors

val dataset = spark.createDataFrame(
  Seq((0, 18, 1.0, Vectors.dense(0.0, 10.0, 0.5), 1.0))
).toDF(&quot;id&quot;, &quot;hour&quot;, &quot;mobile&quot;, &quot;userFeatures&quot;, &quot;clicked&quot;)

val assembler = new VectorAssembler()
  .setInputCols(Array(&quot;hour&quot;, &quot;mobile&quot;, &quot;userFeatures&quot;))
  .setOutputCol(&quot;features&quot;) // output column

val output = assembler.transform(dataset) // transform the dataset

println(&quot;Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'&quot;)
output.select(&quot;features&quot;, &quot;clicked&quot;).show(false)

</code></pre>
<h3 id="vectorindexer"><a class="header" href="#vectorindexer">VectorIndexer</a></h3>
<h3 id="linear-regression"><a class="header" href="#linear-regression">Linear Regression</a></h3>
<pre><code class="language-scala">import org.apache.spark.ml.regression.LinearRegression

// Load training data
val training = spark.read.format(&quot;libsvm&quot;)
  .load(&quot;data/mllib/sample_linear_regression_data.txt&quot;)

val lr = new LinearRegression()
  .setMaxIter(10)
  .setRegParam(0.3)
  .setElasticNetParam(0.8)

// Fit the model
val lrModel = lr.fit(training)

// Print the coefficients and intercept for linear regression
println(s&quot;Coefficients: ${lrModel.coefficients} Intercept: ${lrModel.intercept}&quot;)

// Summarize the model over the training set and print out some metrics
val trainingSummary = lrModel.summary
println(s&quot;numIterations: ${trainingSummary.totalIterations}&quot;)
println(s&quot;objectiveHistory: [${trainingSummary.objectiveHistory.mkString(&quot;,&quot;)}]&quot;)
trainingSummary.residuals.show()
println(s&quot;RMSE: ${trainingSummary.rootMeanSquaredError}&quot;)
println(s&quot;r2: ${trainingSummary.r2}&quot;)

</code></pre>
<h3 id="ml-pipelines"><a class="header" href="#ml-pipelines">ML Pipelines</a></h3>
<p>ML Pipelines provide a uniform set of high-level APIs built on top of DataFrames that help users create and tune practical machine learning pipelines.</p>
<p><img src="https://spark.apache.org/docs/3.2.0/img/ml-Pipeline.png" alt="ML Pipelines" /></p>
<pre><code class="language-scala">from pyspark.ml import Pipeline
// setup the pipeline
featurizationPipeline = Pipeline(stages=[ ])

// fitting 
featurizationPipeline.fit(df).transform(df)

</code></pre>
<pre><code class="language-scala">
import org.apache.spark.ml.{Pipeline, PipelineModel}
import org.apache.spark.ml.classification.LogisticRegression
import org.apache.spark.ml.feature.{HashingTF, Tokenizer}
import org.apache.spark.ml.linalg.Vector
import org.apache.spark.sql.Row

// Prepare training documents from a list of (id, text, label) tuples.
val training = spark.createDataFrame(Seq(
  (0L, &quot;a b c d e spark&quot;, 1.0),
  (1L, &quot;b d&quot;, 0.0),
  (2L, &quot;spark f g h&quot;, 1.0),
  (3L, &quot;hadoop mapreduce&quot;, 0.0)
)).toDF(&quot;id&quot;, &quot;text&quot;, &quot;label&quot;)

// Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.
val tokenizer = new Tokenizer()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;words&quot;)
val hashingTF = new HashingTF()
  .setNumFeatures(1000)
  .setInputCol(tokenizer.getOutputCol)
  .setOutputCol(&quot;features&quot;)
val lr = new LogisticRegression()
  .setMaxIter(10)
  .setRegParam(0.001)
val pipeline = new Pipeline()
  .setStages(Array(tokenizer, hashingTF, lr))

// Fit the pipeline to training documents.
val model = pipeline.fit(training)

// Now we can optionally save the fitted pipeline to disk
model.write.overwrite().save(&quot;/tmp/spark-logistic-regression-model&quot;)

// We can also save this unfit pipeline to disk
pipeline.write.overwrite().save(&quot;/tmp/unfit-lr-model&quot;)

// And load it back in during production
val sameModel = PipelineModel.load(&quot;/tmp/spark-logistic-regression-model&quot;)

// Prepare test documents, which are unlabeled (id, text) tuples.
val test = spark.createDataFrame(Seq(
  (4L, &quot;spark i j k&quot;),
  (5L, &quot;l m n&quot;),
  (6L, &quot;spark hadoop spark&quot;),
  (7L, &quot;apache hadoop&quot;)
)).toDF(&quot;id&quot;, &quot;text&quot;)

// Make predictions on test documents.
model.transform(test)
  .select(&quot;id&quot;, &quot;text&quot;, &quot;probability&quot;, &quot;prediction&quot;)
  .collect()
  .foreach { case Row(id: Long, text: String, prob: Vector, prediction: Double) =&gt;
    println(s&quot;($id, $text) --&gt; prob=$prob, prediction=$prediction&quot;)
  }

</code></pre>
<h2 id="featurization"><a class="header" href="#featurization">Featurization:</a></h2>
<ul>
<li>Encoding categorical variables</li>
<li>Normalizing</li>
<li>Creating new features</li>
<li>Handling missing values</li>
<li>Binning/discretizing</li>
</ul>
<p><img src="img/spark-ml-test-1.png" alt="Spark ML test and train split" /></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->

                            <a rel="next" href="scala.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

                    <a rel="next" href="scala.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script type="text/javascript">
            var socket = new WebSocket("ws://localhost:3010/__livereload");
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>
